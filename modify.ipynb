{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeStopWord():\n",
    "   f = open(\"../StopWords/vietnamese-stopwords-dash.txt\", \"r\")\n",
    "   stopWords = f.readlines()\n",
    "   for idx,line  in enumerate(stopWords):\n",
    "      stopWords[idx] = line.replace(\"\\n\", \"\").strip()\n",
    "      if (len(stopWords[idx]) <= 0):\n",
    "         stopWords.pop(idx)\n",
    "   return stopWords\n",
    "\n",
    "stopWords = removeStopWord()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count = 0\n",
    "train_text = train_data['title'].to_list()\n",
    "train_labels = train_data['label'].to_list()\n",
    "train_text = [re.sub(r'^\\s+|\\s+$', '', str(t)) for t in train_text]\n",
    "train_text = [str(t).strip() for t in train_text]\n",
    "train_text = [re.sub(r'\\s\\s+', ' ', str(t)) for t in train_text]\n",
    "train_text = [re.sub(r'\\n', ' ', str(t)) for t in train_text]\n",
    "train_text = [rdrsegmenter.tokenize(t) for t in train_text]\n",
    "for idx, text in enumerate(train_text):\n",
    "   for idx2, text2 in enumerate(text):\n",
    "         for idx3, text3 in enumerate(text2):\n",
    "            if text3 in stopWords:\n",
    "               text2.pop(idx3)\n",
    "         if len(text2) <= 0:\n",
    "            text.pop(idx2)\n",
    "   if len(text) <= 0:\n",
    "      train_text.pop(idx)\n",
    "      train_labels.pop(idx)\n",
    "for idx, text in enumerate(train_text):\n",
    "   tmp = []\n",
    "   for idx2, text2 in enumerate(text):\n",
    "      tmp2 = []\n",
    "      for idx3, text3 in enumerate(text2):\n",
    "         if not text3.startswith(\"'\") and text3 not in string.punctuation:\n",
    "            tmp2.append(\" \"+text3)\n",
    "         else:\n",
    "            tmp2.append(text3)\n",
    "      tmp.append(\"\".join(tmp2).strip())\n",
    "   train_text[idx] = \" \".join(tmp).strip()\n",
    "\n",
    "# with open('./train.txt', 'w') as obj:\n",
    "#   for i in range(train_data.shape[0]):\n",
    "#     obj.write('train_{}'.format(count))\n",
    "#     obj.write('\\n')\n",
    "#     obj.write(str(title[i]))\n",
    "#     obj.write('\\n')\n",
    "#     obj.write(str(label[i]))\n",
    "#     obj.write('\\n\\n')\n",
    "#     count += 1\n",
    "\n",
    "# count = 0\n",
    "test_text = test_data['title'].to_list()\n",
    "test_labels = test_data['label'].to_list()\n",
    "test_text = [re.sub(r'^\\s+|\\s+$', '', str(t)) for t in test_text]\n",
    "test_text = [str(t).strip() for t in test_text]\n",
    "test_text = [re.sub(r'\\s\\s+', ' ', str(t)) for t in test_text]\n",
    "test_text = [re.sub(r'\\n', ' ', str(t)) for t in test_text]\n",
    "test_text = [rdrsegmenter.tokenize(t) for t in test_text]\n",
    "for idx, text in enumerate(test_text):\n",
    "   for idx2, text2 in enumerate(text):\n",
    "         for idx3, text3 in enumerate(text2):\n",
    "            if text3 in stopWords:\n",
    "               text2.pop(idx3)\n",
    "         if len(text2) <= 0:\n",
    "            text.pop(idx2)\n",
    "   if len(text) <= 0:\n",
    "      test_text.pop(idx)\n",
    "      test_labels.pop(idx)\n",
    "for idx, text in enumerate(test_text):\n",
    "   tmp = []\n",
    "   for idx2, text2 in enumerate(text):\n",
    "      tmp2 = []\n",
    "      for idx3, text3 in enumerate(text2):\n",
    "         if not text3.startswith(\"'\") and text3 not in string.punctuation:\n",
    "            tmp2.append(\" \"+text3)\n",
    "         else:\n",
    "            tmp2.append(text3)\n",
    "      tmp.append(\"\".join(tmp2).strip())\n",
    "   test_text[idx] = \" \".join(tmp).strip()\n",
    "\n",
    "# with open('./test.txt', 'w') as obj:\n",
    "#   for i in range(test_data.shape[0]):\n",
    "#     obj.write('test_{}'.format(count))\n",
    "#     obj.write('\\n')\n",
    "#     obj.write(str(title[i]))\n",
    "#     obj.write('\\n')\n",
    "#     obj.write(str(label[i]))\n",
    "#     obj.write('\\n\\n')\n",
    "#     count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_path = './train.txt'\n",
    "# test_path = './test.txt'\n",
    "\n",
    "# train_id, train_text, train_labels = [], [], []\n",
    "# test_id, test_text, test_labels = [], [], []\n",
    "\n",
    "# with open(train_path, 'r') as f_r:\n",
    "#     data1 = f_r.read().strip()\n",
    "\n",
    "#     data = re.findall('train_[\\s\\S]+?\\n.*\\n[0-8]\\n\\n', data1)\n",
    "\n",
    "#     for sample in data:\n",
    "#         splits = sample.strip().split('\\n')\n",
    "#         # print(splits)\n",
    "#         id = splits[0]\n",
    "#         label = int(splits[-1])\n",
    "#         # print(label)\n",
    "#         text = ' '.join(splits[1:-1])\n",
    "#         text = rdrsegmenter.tokenize(text)\n",
    "#         text = ' '.join([' '.join(x) for x in text])\n",
    "\n",
    "#         train_id.append(id)\n",
    "#         train_text.append(text)\n",
    "#         train_labels.append(label)\n",
    "\n",
    "\n",
    "# with open(test_path, 'r') as f_r:\n",
    "#     data1 = f_r.read().strip()\n",
    "#     data = re.findall('test_[\\s\\S]+?\\n.*\\n[0-8]\\n\\n', data1)\n",
    "\n",
    "#     for sample in data:\n",
    "#         splits = sample.strip().split('\\n')\n",
    "\n",
    "#         id = splits[0]\n",
    "#         label = int(splits[-1])\n",
    "#         text = ' '.join(splits[1:-1])\n",
    "#         text = rdrsegmenter.tokenize(text)\n",
    "#         text = ' '.join([' '.join(x) for x in text])\n",
    "\n",
    "#         test_id.append(id)\n",
    "#         test_text.append(text)\n",
    "#         test_labels.append(label)\n",
    "\n",
    "# for i in range(len(train_labels)):\n",
    "#   train_labels[i] = train_labels[i] \n",
    "\n",
    "# for i in range(len(test_labels)):\n",
    "#   test_labels[i] = test_labels[i]\n",
    "# print(train_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 (conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "36b5d234dcadb63a5dcffe129e6467f293a83c75bbea9a5662c39cecefcc4dbb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
